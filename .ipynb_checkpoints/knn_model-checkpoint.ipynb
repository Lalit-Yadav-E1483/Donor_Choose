{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import re\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from chart_studio import plotly\n",
    "import plotly.offline as offline\n",
    "import plotly.graph_objs as go\n",
    "offline.init_notebook_mode()\n",
    "from collections import Counter\n",
    "from pathlib2 import Path\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from scipy.sparse import hstack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('data')\n",
    "list(path.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'preprocessed_data.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['project_is_approved'].values\n",
    "X = df.drop(['project_is_approved'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into Train and cross validation(or test): Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train)\n",
    "print(X_train.shape, y_train.shape), print(X_cv.shape, y_cv.shape), print(X_test.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Data Model Ready: encoding eassay, and project_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=10, ngram_range=(1,4), max_features=5000)\n",
    "X_train_essay_bow = vectorizer.fit_transform(X_train['essay'].values)\n",
    "X_cv_essay_bow = vectorizer.transform(X_cv['essay'].values)\n",
    "X_test_essay_bow = vectorizer.transform(X_test['essay'].values)\n",
    "\n",
    "print(X_train_essay_bow.shape, y_train.shape)\n",
    "print(X_cv_essay_bow.shape, y_cv.shape)\n",
    "print(X_test_essay_bow.shape, y_test.shape)\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_train['school_state'].values)\n",
    "\n",
    "X_train_state_ohe = vectorizer.transform(X_train['school_state'].values)\n",
    "X_cv_state_ohe = vectorizer.transform(X_cv['school_state'].values)\n",
    "X_test_state_ohe = vectorizer.transform(X_test['school_state'].values)\n",
    "\n",
    "print(X_train_state_ohe.shape, y_train.shape)\n",
    "print(X_cv_state_ohe.shape, y_cv.shape)\n",
    "print(X_test_state_ohe.shape, y_test.shape)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding categorical features: teacher_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_train['teacher_prefix'].values)\n",
    "\n",
    "X_train_teacher_ohe = vectorizer.transform(X_train['teacher_prefix'].values)\n",
    "X_cv_teacher_ohe = vectorizer.transform(X_cv['teacher_prefix'].values)\n",
    "X_test_teacher_ohe = vectorizer.transform(X_test['teacher_prefix'].values)\n",
    "\n",
    "print(X_train_teacher_ohe.shape, y_train.shape)\n",
    "print(X_cv_teacher_ohe.shape, y_cv.shape)\n",
    "print(X_test_teacher_ohe.shape, y_test.shape)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### encoding categorical features: project_grade_categor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_train['project_grade_category'].values)\n",
    "\n",
    "X_train_project_ohe = vectorizer.transform(X_train['project_grade_category'].values)\n",
    "X_cv_project_ohe = vectorizer.transform(X_cv['project_grade_category'].values)\n",
    "X_test_project_ohe = vectorizer.transform(X_test['project_grade_category'].values)\n",
    "\n",
    "print(X_train_project_ohe.shape, y_train.shape)\n",
    "print(X_cv_project_ohe.shape, y_cv.shape)\n",
    "print(X_test_project_ohe.shape, y_test.shape)\n",
    "print(vectorizer.get_feature_names())\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "\n",
    "normalizer.fit(X_train['price'].values.reshape(-1,1))\n",
    "\n",
    "X_train_price_norm = normalizer.transform(X_train['price'].values.reshape(-1,1))\n",
    "X_cv_price_norm = normalizer.transform(X_cv['price'].values.reshape(-1,1))\n",
    "X_test_price_norm = normalizer.transform(X_test['price'].values.reshape(-1,1))\n",
    "\n",
    "print(X_train_price_norm.shape, y_train.shape)\n",
    "print(X_cv_price_norm.shape, y_cv.shape)\n",
    "print(X_test_price_norm.shape, y_test.shape)\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize teacher_number_of_previously_posted_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "\n",
    "normalizer.fit(X_train['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
    "\n",
    "X_train_prev_proj_norm = normalizer.transform(X_train['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
    "X_cv_prev_proj_norm = normalizer.transform(X_cv['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
    "X_test_prev_proj_norm = normalizer.transform(X_test['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
    "\n",
    "print(X_train_prev_proj_norm.shape, y_train.shape)\n",
    "print(X_cv_prev_proj_norm.shape, y_cv.shape)\n",
    "print(X_test_prev_proj_norm.shape, y_test.shape)\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categories and sub categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=10, ngram_range=(1,4), max_features=5000)\n",
    "X_train_categories_bow = vectorizer.fit_transform(X_train['clean_categories'].values)\n",
    "X_cv_categories_bow = vectorizer.transform(X_cv['clean_categories'].values)\n",
    "X_test_categories_bow = vectorizer.transform(X_test['clean_categories'].values)\n",
    "\n",
    "print(X_train_categories_bow.shape, y_train.shape)\n",
    "print(X_cv_categories_bow.shape, y_cv.shape)\n",
    "print(X_test_categories_bow.shape, y_test.shape)\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=10, ngram_range=(1,4), max_features=5000)\n",
    "X_train_subcategories_bow = vectorizer.fit_transform(X_train['clean_subcategories'].values)\n",
    "X_cv_subcategories_bow = vectorizer.transform(X_cv['clean_subcategories'].values)\n",
    "X_test_subcategories_bow = vectorizer.transform(X_test['clean_subcategories'].values)\n",
    "\n",
    "print(X_train_subcategories_bow.shape, y_train.shape)\n",
    "print(X_cv_subcategories_bow.shape, y_cv.shape)\n",
    "print(X_test_subcategories_bow.shape, y_test.shape)\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = hstack((X_train_essay_bow, X_train_categories_bow, X_train_subcategories_bow, X_train_state_ohe, X_train_teacher_ohe, X_train_project_ohe, X_train_price_norm, X_train_prev_proj_norm))\n",
    "X_cr = hstack((X_cv_essay_bow, X_cv_categories_bow, X_cv_subcategories_bow, X_cv_state_ohe, X_cv_teacher_ohe, X_cv_project_ohe, X_cv_price_norm, X_cv_prev_proj_norm))\n",
    "X_te = hstack((X_test_essay_bow, X_test_categories_bow, X_test_subcategories_bow, X_test_state_ohe, X_test_teacher_ohe, X_test_project_ohe, X_test_price_norm, X_test_prev_proj_norm))\n",
    "\n",
    "print(\"Final Data matrix\")\n",
    "print(X_tr.shape, y_train.shape)\n",
    "print(X_cr.shape, y_cv.shape)\n",
    "print(X_te.shape, y_test.shape)\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying KNN of the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "def batch_predict(clf, data):\n",
    "    pdb.set_trace()\n",
    "    y_data_pred = []\n",
    "    tr_loop = data.shape[0] - data.shape[0] % 1000\n",
    "    for i in range(0, tr_loop, 1000):\n",
    "        y_data_pred.extend(clf.predict_proba(data[i:i+1000])[:,1])\n",
    "    if data.shape[0] % 1000 != 0:\n",
    "        y_data_pred.extend(clf.predict_proba(data[tr_loop:])[:,1])\n",
    "    \n",
    "    return y_data_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_auc = []\n",
    "cv_auc = []\n",
    "K = [3, 15, 25, 51, 101]\n",
    "for i in tqdm(K):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=i, n_jobs=4)\n",
    "    neigh.fit(X_tr, y_train)\n",
    "    \n",
    "    y_train_pred = batch_predict(neigh, X_tr)\n",
    "    y_cv_pred = batch_predict(neigh, X_cr)\n",
    "    \n",
    "    train_auc.append(roc_auc_score(y_train, y_train_pred))\n",
    "    cv_auc.append(roc_auc_score(y_cv, y_cv_pred))\n",
    "    \n",
    "plt.plot(K, train_auc, label='Train AUC')\n",
    "plt.plot(K, cv_auc, label='CV AUC')\n",
    "\n",
    "plt.scatter(K, train_auc, label='Train AUC points')\n",
    "plt.scatter(K, cv_auc, label='CV AUC points')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"K: hyperparameter\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.title(\"ERROR PLOTS\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
